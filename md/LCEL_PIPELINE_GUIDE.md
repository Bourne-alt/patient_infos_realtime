# LangChain Expression Language (LCEL) ç®¡é“æ“ä½œç¬¦æŒ‡å—

## ğŸš€ ä»€ä¹ˆæ˜¯ LCELï¼Ÿ

LangChain Expression Language (LCEL) æ˜¯ LangChain çš„ç°ä»£è¯­æ³•ï¼Œä½¿ç”¨ `|` ç®¡é“æ“ä½œç¬¦å°†ä¸åŒçš„ç»„ä»¶é“¾æ¥åœ¨ä¸€èµ·ã€‚è¿™ç§è¯­æ³•æ›´ç®€æ´ã€æ›´ç›´è§‚ï¼Œä¹Ÿæ›´å®¹æ˜“ç†è§£å’Œç»´æŠ¤ã€‚

## ğŸ”„ ä¼ ç»Ÿè¯­æ³• vs LCEL è¯­æ³•

### ä¼ ç»Ÿè¯­æ³•ï¼š
```python
# ä¼ ç»Ÿæ–¹å¼
prompt = PromptTemplate(...)
chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run({"input": "ç—‡çŠ¶æè¿°"})
```

### LCEL è¯­æ³•ï¼š
```python
# ç°ä»£ LCEL æ–¹å¼
chain = prompt | llm | StrOutputParser()
result = chain.invoke({"input": "ç—‡çŠ¶æè¿°"})
```

## ğŸ“Š LCEL çš„ä¸»è¦ç»„ä»¶

### 1. åŸºç¡€ç»„ä»¶

| ç»„ä»¶ | ä½œç”¨ | ç¤ºä¾‹ |
|------|------|------|
| `PromptTemplate` | åˆ›å»ºæç¤ºæ¨¡æ¿ | `PromptTemplate.from_template("åˆ†æç—‡çŠ¶ï¼š{symptoms}")` |
| `ChatOpenAI/OpenAI` | å¤§è¯­è¨€æ¨¡å‹ | `ChatOpenAI(model="gpt-4o")` |
| `StrOutputParser()` | å­—ç¬¦ä¸²è¾“å‡ºè§£æå™¨ | å°†LLMè¾“å‡ºè½¬æ¢ä¸ºå­—ç¬¦ä¸² |
| `RunnablePassthrough` | æ•°æ®ä¼ é€’ | ä¸æ”¹å˜æ•°æ®ï¼Œç›´æ¥ä¼ é€’ |
| `RunnableParallel` | å¹¶è¡Œæ‰§è¡Œ | åŒæ—¶æ‰§è¡Œå¤šä¸ªæ“ä½œ |

### 2. æ•°æ®æ“ä½œç¬¦

| æ“ä½œç¬¦ | ä½œç”¨ | è¯­æ³• |
|--------|------|------|
| `\|` | ç®¡é“è¿æ¥ | `a \| b \| c` |
| `{}` | æ•°æ®å­—å…¸ | `{"key": value}` |
| `assign()` | æ·»åŠ æ–°å­—æ®µ | `RunnablePassthrough.assign(new_field=...)` |

## ğŸ¯ LCEL ä½¿ç”¨æ¨¡å¼

### 1. ç®€å•ç®¡é“
æœ€åŸºç¡€çš„ä½¿ç”¨æ¨¡å¼ï¼š

```python
simple_chain = (
    PromptTemplate.from_template("åˆ†æç—‡çŠ¶ï¼š{symptoms}")
    | llm
    | StrOutputParser()
)

result = simple_chain.invoke({"symptoms": "å¤´ç—›ã€å‘çƒ­"})
```

**ä¼˜åŠ¿**ï¼š
- è¯­æ³•ç®€æ´æ˜äº†
- æ˜“äºç†è§£å’Œä¿®æ”¹
- æ”¯æŒæµå¼å¤„ç†

### 2. å¹¶è¡Œå¤„ç†ç®¡é“
åŒæ—¶æ‰§è¡Œå¤šä¸ªåˆ†æï¼š

```python
parallel_chain = RunnableParallel(
    internal_medicine=(
        PromptTemplate.from_template("å†…ç§‘è§’åº¦ï¼š{symptoms}")
        | llm
        | StrOutputParser()
    ),
    emergency=(
        PromptTemplate.from_template("æ€¥è¯Šè§’åº¦ï¼š{symptoms}")
        | llm
        | StrOutputParser()
    )
)

result = parallel_chain.invoke({"symptoms": "èƒ¸ç—›"})
# è¾“å‡º: {"internal_medicine": "...", "emergency": "..."}
```

**ä¼˜åŠ¿**ï¼š
- å¹¶è¡Œæ‰§è¡Œï¼Œæé«˜æ•ˆç‡
- å¤šè§’åº¦åˆ†æ
- ç»“æœç»“æ„åŒ–

### 3. å¤æ‚æ•°æ®æµç®¡é“
å¤šæ­¥éª¤å¤„ç†ï¼ŒåŒ…å«æ•°æ®ä¼ é€’å’Œè½¬æ¢ï¼š

```python
complex_chain = (
    {
        "patient_info": extract_prompt | llm | StrOutputParser(),
        "original": RunnablePassthrough()
    }
    | RunnablePassthrough.assign(
        analysis=analysis_prompt | llm | StrOutputParser()
    )
    | final_prompt
    | llm
    | StrOutputParser()
)
```

**æ•°æ®æµï¼š**
1. ç¬¬ä¸€æ­¥ï¼šæå–æ‚£è€…ä¿¡æ¯ + ä¿ç•™åŸå§‹æ•°æ®
2. ç¬¬äºŒæ­¥ï¼šåŸºäºæ‚£è€…ä¿¡æ¯è¿›è¡Œåˆ†æ
3. ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š

### 4. æ¡ä»¶è·¯ç”±ç®¡é“
æ ¹æ®æ¡ä»¶é€‰æ‹©ä¸åŒçš„å¤„ç†è·¯å¾„ï¼š

```python
def route_by_severity(inputs):
    symptoms = inputs["symptoms"]
    if "å‰§çƒˆ" in symptoms or "æ€¥æ€§" in symptoms:
        return "emergency"
    else:
        return "routine"

# ä¸åŒä¸¥é‡ç¨‹åº¦çš„å¤„ç†ç®¡é“
emergency_chain = emergency_prompt | llm | StrOutputParser()
routine_chain = routine_prompt | llm | StrOutputParser()

# æ ¹æ®è·¯ç”±ç»“æœé€‰æ‹©å¤„ç†é“¾
def process_by_route(inputs):
    route = route_by_severity(inputs)
    if route == "emergency":
        return emergency_chain.invoke(inputs)
    else:
        return routine_chain.invoke(inputs)
```

### 5. è®°å¿†ç®¡é“
ä¿æŒå¯¹è¯ä¸Šä¸‹æ–‡ï¼š

```python
memory_chain = (
    {
        "input": lambda x: x["input"],
        "chat_history": lambda x: x.get("history", [])
    }
    | PromptTemplate.from_template(
        "å†å²: {chat_history}\né—®é¢˜: {input}\nå›ç­”:"
    )
    | llm
    | StrOutputParser()
)
```

## ğŸ› ï¸ å®é™…åº”ç”¨ç¤ºä¾‹

### åŒ»ç–—è¯Šæ–­å·¥ä½œæµ

```python
# å®Œæ•´çš„åŒ»ç–—è¯Šæ–­ LCEL å·¥ä½œæµ
medical_diagnosis_chain = (
    # ç¬¬ä¸€æ­¥ï¼šä¿¡æ¯æå–å’Œæ ‡å‡†åŒ–
    {
        "patient_info": (
            PromptTemplate.from_template(
                "æå–æ‚£è€…ä¿¡æ¯ï¼š{raw_input}\næ ¼å¼ï¼šå¹´é¾„ã€æ€§åˆ«ã€ç—‡çŠ¶"
            )
            | llm
            | StrOutputParser()
        ),
        "original_input": RunnablePassthrough()
    }
    
    # ç¬¬äºŒæ­¥ï¼šå¤šè§’åº¦å¹¶è¡Œåˆ†æ
    | RunnablePassthrough.assign(
        multi_analysis=RunnableParallel(
            primary_care=(
                PromptTemplate.from_template(
                    "å…¨ç§‘åŒ»ç”Ÿè§†è§’åˆ†æï¼š{patient_info}"
                )
                | llm
                | StrOutputParser()
            ),
            specialist=(
                PromptTemplate.from_template(
                    "ä¸“ç§‘åŒ»ç”Ÿè§†è§’åˆ†æï¼š{patient_info}"
                )
                | llm
                | StrOutputParser()
            ),
            emergency=(
                PromptTemplate.from_template(
                    "æ€¥è¯Šç§‘è§†è§’è¯„ä¼°ï¼š{patient_info}"
                )
                | llm
                | StrOutputParser()
            )
        )
    )
    
    # ç¬¬ä¸‰æ­¥ï¼šç»¼åˆè¯Šæ–­æŠ¥å‘Š
    | PromptTemplate.from_template(
        """æ‚£è€…ä¿¡æ¯ï¼š{patient_info}
        
        å¤šè§’åº¦åˆ†æï¼š
        - å…¨ç§‘è§‚ç‚¹ï¼š{multi_analysis[primary_care]}
        - ä¸“ç§‘è§‚ç‚¹ï¼š{multi_analysis[specialist]}  
        - æ€¥è¯Šè§‚ç‚¹ï¼š{multi_analysis[emergency]}
        
        è¯·ç”Ÿæˆç»¼åˆè¯Šæ–­æŠ¥å‘Šï¼š"""
    )
    | llm
    | StrOutputParser()
)

# ä½¿ç”¨å·¥ä½œæµ
result = medical_diagnosis_chain.invoke({
    "raw_input": "35å²å¥³æ€§ï¼ŒæŒç»­å¤´ç—›3å¤©ï¼Œä¼´æœ‰æ¶å¿ƒå‘•å"
})
```

## ğŸ¨ LCEL æœ€ä½³å®è·µ

### 1. å¯è¯»æ€§ä¼˜åŒ–
```python
# å¥½çš„å†™æ³•ï¼šåˆ†å±‚æ¸…æ™°
chain = (
    prompt_template
    | llm
    | StrOutputParser()
)

# æ›´å¥½çš„å†™æ³•ï¼šæ·»åŠ æ³¨é‡Š
chain = (
    prompt_template        # æ„å»ºæç¤º
    | llm                 # LLMå¤„ç†
    | StrOutputParser()   # è¾“å‡ºè§£æ
)
```

### 2. é”™è¯¯å¤„ç†
```python
from langchain.schema.runnable import RunnableLambda

def safe_parse(text):
    try:
        return json.loads(text)
    except:
        return {"error": "è§£æå¤±è´¥", "raw": text}

safe_chain = (
    prompt
    | llm
    | RunnableLambda(safe_parse)
)
```

### 3. æµå¼å¤„ç†
```python
# æ”¯æŒæµå¼è¾“å‡º
async def stream_medical_analysis():
    chain = prompt | llm | StrOutputParser()
    
    async for chunk in chain.astream({"symptoms": "å¤´ç—›"}):
        print(chunk, end="", flush=True)
```

### 4. æ‰¹å¤„ç†
```python
# æ‰¹é‡å¤„ç†å¤šä¸ªæ‚£è€…
patients = [
    {"symptoms": "å¤´ç—›"},
    {"symptoms": "å‘çƒ­"},
    {"symptoms": "å’³å—½"}
]

results = chain.batch(patients)
```

## ğŸ”§ è°ƒè¯•å’Œç›‘æ§

### 1. å¯ç”¨è¯¦ç»†è¾“å‡º
```python
chain = (
    prompt
    | llm.with_config({"verbose": True})
    | StrOutputParser()
)
```

### 2. æ·»åŠ ä¸­é—´è¾“å‡º
```python
def debug_print(x):
    print(f"Debug: {x}")
    return x

chain = (
    prompt
    | llm
    | RunnableLambda(debug_print)
    | StrOutputParser()
)
```

### 3. æ€§èƒ½ç›‘æ§
```python
import time

def time_component(component_name):
    def wrapper(x):
        start = time.time()
        result = x
        end = time.time()
        print(f"{component_name}: {end - start:.2f}s")
        return result
    return RunnableLambda(wrapper)

chain = (
    prompt
    | time_component("LLMå¤„ç†")
    | llm
    | time_component("è¾“å‡ºè§£æ")
    | StrOutputParser()
)
```

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

| ç‰¹æ€§ | ä¼ ç»Ÿé“¾å¼è°ƒç”¨ | LCEL ç®¡é“ |
|------|-------------|-----------|
| è¯­æ³•ç®€æ´æ€§ | â­â­â­ | â­â­â­â­â­ |
| å¯è¯»æ€§ | â­â­â­ | â­â­â­â­â­ |
| æµå¼æ”¯æŒ | â­â­ | â­â­â­â­â­ |
| å¹¶è¡Œå¤„ç† | â­â­ | â­â­â­â­â­ |
| é”™è¯¯å¤„ç† | â­â­â­ | â­â­â­â­ |
| è°ƒè¯•ä¾¿åˆ©æ€§ | â­â­ | â­â­â­â­ |
| æ€§èƒ½ | â­â­â­â­ | â­â­â­â­â­ |

## ğŸš€ è¿ç§»æŒ‡å—

### ä»ä¼ ç»Ÿè¯­æ³•è¿ç§»åˆ° LCEL

#### 1. ç®€å•é“¾è¿ç§»
**ä¹‹å‰ï¼š**
```python
prompt = PromptTemplate(...)
chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run(inputs)
```

**ä¹‹åï¼š**
```python
chain = prompt | llm | StrOutputParser()
result = chain.invoke(inputs)
```

#### 2. é¡ºåºé“¾è¿ç§»
**ä¹‹å‰ï¼š**
```python
chain1 = LLMChain(...)
chain2 = LLMChain(...)
sequential = SequentialChain(chains=[chain1, chain2])
```

**ä¹‹åï¼š**
```python
chain = (
    prompt1 | llm | StrOutputParser()
    | RunnablePassthrough.assign(
        step2=prompt2 | llm | StrOutputParser()
    )
)
```

#### 3. è·¯ç”±é“¾è¿ç§»
**ä¹‹å‰ï¼š**
```python
router_chain = MultiRouteChain(
    router_chain=router,
    destination_chains=destinations
)
```

**ä¹‹åï¼š**
```python
def route_and_process(inputs):
    route = router_function(inputs)
    return destination_pipelines[route].invoke(inputs)

chain = RunnableLambda(route_and_process)
```

## ğŸ’¡ å¸¸è§é—®é¢˜

### Q: ä»€ä¹ˆæ—¶å€™ä½¿ç”¨ LCELï¼Ÿ
A: 
- æ–°é¡¹ç›®å»ºè®®ç›´æ¥ä½¿ç”¨ LCEL
- éœ€è¦æµå¼å¤„ç†æ—¶
- è¦è¿›è¡Œå¹¶è¡Œå¤„ç†æ—¶
- å¸Œæœ›ä»£ç æ›´ç®€æ´æ—¶

### Q: LCEL å…¼å®¹æ€§å¦‚ä½•ï¼Ÿ
A: LCEL æ˜¯ LangChain 0.1+ çš„æ ‡å‡†è¯­æ³•ï¼Œå‘åå…¼å®¹ä¼ ç»Ÿè¯­æ³•

### Q: å¦‚ä½•å¤„ç†å¤æ‚çš„æ¡ä»¶é€»è¾‘ï¼Ÿ
A: ä½¿ç”¨ `RunnableLambda` åŒ…è£…è‡ªå®šä¹‰å‡½æ•°ï¼Œæˆ–ç»„åˆå¤šä¸ªæ¡ä»¶ç®¡é“

### Q: LCEL æ”¯æŒå¼‚æ­¥å—ï¼Ÿ
A: å®Œå…¨æ”¯æŒï¼Œä½¿ç”¨ `astream()`, `ainvoke()`, `abatch()` ç­‰å¼‚æ­¥æ–¹æ³•

## ğŸ¯ æ€»ç»“

LCEL ç®¡é“æ“ä½œç¬¦æä¾›äº†ï¼š

1. **ç®€æ´çš„è¯­æ³•** - ä½¿ç”¨ `|` è¿æ¥ç»„ä»¶
2. **å¼ºå¤§çš„å¹¶è¡Œå¤„ç†** - `RunnableParallel` æ”¯æŒ
3. **çµæ´»çš„æ•°æ®æµ** - `RunnablePassthrough` å’Œ `assign()`
4. **ä¼˜ç§€çš„æµå¼æ”¯æŒ** - åŸç”Ÿæ”¯æŒæµå¼è¾“å‡º
5. **æ˜“äºè°ƒè¯•** - æ¸…æ™°çš„æ•°æ®æµå‘
6. **é«˜æ€§èƒ½** - è‡ªåŠ¨ä¼˜åŒ–æ‰§è¡Œ

è¿™ä½¿å¾— LangChain å·¥ä½œæµçš„æ„å»ºå˜å¾—æ›´åŠ ç°ä»£åŒ–å’Œé«˜æ•ˆï¼ 