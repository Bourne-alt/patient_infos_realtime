"""
LangChain é“¾å¼å·¥ä½œæµæ ·ä¾‹ä»£ç 
å±•ç¤º8ç§å·¥ä½œæµæ¨¡å¼ï¼šç®€å•é“¾ã€é¡ºåºé“¾ã€åˆ†æ”¯é“¾ã€è®°å¿†é“¾ã€è§£æå™¨é“¾ã€Agentå·¥ä½œæµã€LCELç®¡é“æ“ä½œç¬¦ã€å¤åˆå·¥ä½œæµç­‰
"""

import os
import asyncio
import logging
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
from dotenv import load_dotenv

# LangChain æ ¸å¿ƒå¯¼å…¥
from langchain.chat_models import ChatOpenAI
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate
from langchain.chains import LLMChain, SequentialChain, RouterChain, MultiRetrievalQAChain
from langchain.chains.router.llm_router import LLMRouterChain
from langchain.chains.router.multi_retrieval_prompt import MULTI_RETRIEVAL_ROUTER_TEMPLATE
from langchain.chains.router import MultiRouteChain
from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory, ConversationBufferWindowMemory
from langchain.schema import BaseOutputParser, OutputParserException
from langchain.callbacks import StdOutCallbackHandler
from langchain.agents import AgentExecutor, create_react_agent, Tool
from langchain.tools import BaseTool
from langchain.schema import AgentAction, AgentFinish
from langchain.agents.react.base import DocstoreExplorer
from langchain.docstore import InMemoryDocstore
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from pydantic import BaseModel, Field

# LCEL (LangChain Expression Language) å¯¼å…¥
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnablePassthrough, RunnableParallel
from langchain.schema.runnable.config import RunnableConfig
from langchain.schema import BaseMessage

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class MedicalWorkflowExample:
    """åŒ»ç–—å·¥ä½œæµæ ·ä¾‹ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–å·¥ä½œæµ"""
        self.api_key = os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.llm = ChatOpenAI(
            openai_api_key=self.api_key,
            model_name="gpt-4o",
            temperature=0.7
        )
        
        self.simple_llm = OpenAI(
            openai_api_key=self.api_key,
            temperature=0.7
        )
        
        # åˆå§‹åŒ–è®°å¿†
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True
        )
        
        logger.info("åŒ»ç–—å·¥ä½œæµåˆå§‹åŒ–å®Œæˆ")
    
    # ==================== 1. ç®€å•é“¾ (Simple Chain) ====================
    def create_simple_chain(self) -> LLMChain:
        """åˆ›å»ºç®€å•é“¾ - æ‚£è€…ç—‡çŠ¶åˆ†æ"""
        
        prompt = PromptTemplate(
            input_variables=["symptoms", "patient_age", "gender"],
            template="""
            ä½œä¸ºä¸€åä¸“ä¸šçš„åŒ»ç–—åŠ©æ‰‹ï¼Œè¯·åˆ†æä»¥ä¸‹æ‚£è€…ä¿¡æ¯ï¼š
            
            æ‚£è€…å¹´é¾„ï¼š{patient_age}
            æ‚£è€…æ€§åˆ«ï¼š{gender}
            ç—‡çŠ¶æè¿°ï¼š{symptoms}
            
            è¯·æä¾›ï¼š
            1. å¯èƒ½çš„è¯Šæ–­æ–¹å‘
            2. å»ºè®®çš„æ£€æŸ¥é¡¹ç›®
            3. æ³¨æ„äº‹é¡¹
            
            å›ç­”ï¼š
            """
        )
        
        chain = LLMChain(
            llm=self.llm,
            prompt=prompt,
            output_key="analysis_result"
        )
        
        return chain
    
    # ==================== 2. é¡ºåºé“¾ (Sequential Chain) ====================
    def create_sequential_chain(self) -> SequentialChain:
        """åˆ›å»ºé¡ºåºé“¾ - å®Œæ•´çš„åŒ»ç–—åˆ†ææµç¨‹"""
        
        # ç¬¬ä¸€æ­¥ï¼šç—‡çŠ¶åˆ†æ
        symptom_analysis_prompt = PromptTemplate(
            input_variables=["symptoms", "patient_info"],
            template="""
            æ‚£è€…ä¿¡æ¯ï¼š{patient_info}
            ç—‡çŠ¶ï¼š{symptoms}
            
            è¯·åˆ†ææ‚£è€…ç—‡çŠ¶ï¼Œæä¾›å¯èƒ½çš„ç–¾ç—…æ–¹å‘ã€‚
            è¾“å‡ºæ ¼å¼ï¼šç®€æ´çš„ç–¾ç—…åˆ†æï¼Œä¸è¶…è¿‡200å­—ã€‚
            """
        )
        
        symptom_chain = LLMChain(
            llm=self.llm,
            prompt=symptom_analysis_prompt,
            output_key="symptom_analysis"
        )
        
        # ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥å»ºè®®
        examination_prompt = PromptTemplate(
            input_variables=["symptom_analysis", "patient_info"],
            template="""
            æ‚£è€…ä¿¡æ¯ï¼š{patient_info}
            ç—‡çŠ¶åˆ†æï¼š{symptom_analysis}
            
            åŸºäºä»¥ä¸Šåˆ†æï¼Œè¯·æ¨èå…·ä½“çš„æ£€æŸ¥é¡¹ç›®å’Œä¼˜å…ˆçº§ã€‚
            è¾“å‡ºæ ¼å¼ï¼šæ£€æŸ¥é¡¹ç›®åˆ—è¡¨ï¼ŒåŒ…å«ä¼˜å…ˆçº§ã€‚
            """
        )
        
        examination_chain = LLMChain(
            llm=self.llm,
            prompt=examination_prompt,
            output_key="examination_plan"
        )
        
        # ç¬¬ä¸‰æ­¥ï¼šæ²»ç–—å»ºè®®
        treatment_prompt = PromptTemplate(
            input_variables=["symptom_analysis", "examination_plan", "patient_info"],
            template="""
            æ‚£è€…ä¿¡æ¯ï¼š{patient_info}
            ç—‡çŠ¶åˆ†æï¼š{symptom_analysis}
            æ£€æŸ¥è®¡åˆ’ï¼š{examination_plan}
            
            è¯·æä¾›åˆæ­¥çš„æ²»ç–—å»ºè®®å’Œç”Ÿæ´»æŒ‡å¯¼ã€‚
            è¾“å‡ºæ ¼å¼ï¼šæ²»ç–—å»ºè®®å’Œæ³¨æ„äº‹é¡¹ã€‚
            """
        )
        
        treatment_chain = LLMChain(
            llm=self.llm,
            prompt=treatment_prompt,
            output_key="treatment_plan"
        )
        
        # ç»„åˆæˆé¡ºåºé“¾
        sequential_chain = SequentialChain(
            chains=[symptom_chain, examination_chain, treatment_chain],
            input_variables=["symptoms", "patient_info"],
            output_variables=["symptom_analysis", "examination_plan", "treatment_plan"],
            verbose=True
        )
        
        return sequential_chain
    
    # ==================== 3. åˆ†æ”¯é“¾ (Router Chain) ====================
    def create_router_chain(self) -> MultiRouteChain:
        """åˆ›å»ºåˆ†æ”¯é“¾ - æ ¹æ®ä¸åŒç§‘å®¤åˆ†å‘æŸ¥è¯¢"""
        
        # å†…ç§‘é“¾
        internal_medicine_prompt = PromptTemplate(
            input_variables=["query"],
            template="""
            ä½œä¸ºå†…ç§‘åŒ»ç”Ÿï¼Œè¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{query}
            
            è¯·ä»å†…ç§‘è§’åº¦æä¾›ä¸“ä¸šçš„åˆ†æå’Œå»ºè®®ã€‚
            """
        )
        
        internal_medicine_chain = LLMChain(
            llm=self.llm,
            prompt=internal_medicine_prompt,
            output_key="result"
        )
        
        # å¤–ç§‘é“¾
        surgery_prompt = PromptTemplate(
            input_variables=["query"],
            template="""
            ä½œä¸ºå¤–ç§‘åŒ»ç”Ÿï¼Œè¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{query}
            
            è¯·ä»å¤–ç§‘è§’åº¦æä¾›ä¸“ä¸šçš„åˆ†æå’Œå»ºè®®ã€‚
            """
        )
        
        surgery_chain = LLMChain(
            llm=self.llm,
            prompt=surgery_prompt,
            output_key="result"
        )
        
        # å„¿ç§‘é“¾
        pediatrics_prompt = PromptTemplate(
            input_variables=["query"],
            template="""
            ä½œä¸ºå„¿ç§‘åŒ»ç”Ÿï¼Œè¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{query}
            
            è¯·ä»å„¿ç§‘è§’åº¦æä¾›ä¸“ä¸šçš„åˆ†æå’Œå»ºè®®ï¼Œç‰¹åˆ«æ³¨æ„å„¿ç«¥çš„ç‰¹æ®Šæ€§ã€‚
            """
        )
        
        pediatrics_chain = LLMChain(
            llm=self.llm,
            prompt=pediatrics_prompt,
            output_key="result"
        )
        
        # é»˜è®¤é“¾
        default_prompt = PromptTemplate(
            input_variables=["query"],
            template="""
            ä½œä¸ºå…¨ç§‘åŒ»ç”Ÿï¼Œè¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{query}
            
            è¯·æä¾›ç»¼åˆçš„åŒ»ç–—å»ºè®®ã€‚
            """
        )
        
        default_chain = LLMChain(
            llm=self.llm,
            prompt=default_prompt,
            output_key="result"
        )
        
        # è·¯ç”±å™¨æ¨¡æ¿
        router_template = """
        ç»™å®šä¸€ä¸ªåŒ»ç–—æŸ¥è¯¢ï¼Œé€‰æ‹©æœ€åˆé€‚çš„ä¸“ç§‘æ¥å›ç­”ã€‚
        
        å¯é€‰ä¸“ç§‘ï¼š
        internal_medicine: å†…ç§‘ç›¸å…³é—®é¢˜ï¼Œå¦‚å‘çƒ­ã€å’³å—½ã€é«˜è¡€å‹ã€ç³–å°¿ç—…ç­‰
        surgery: å¤–ç§‘ç›¸å…³é—®é¢˜ï¼Œå¦‚å¤–ä¼¤ã€æ‰‹æœ¯ã€ç–¼ç—›ç­‰
        pediatrics: å„¿ç§‘ç›¸å…³é—®é¢˜ï¼Œæ¶‰åŠå„¿ç«¥æ‚£è€…
        
        æŸ¥è¯¢: {input}
        
        è¯·é€‰æ‹©: internal_medicine, surgery, pediatrics ä¸­çš„ä¸€ä¸ªï¼Œæˆ–é€‰æ‹© DEFAULT
        """
        
        router_prompt = PromptTemplate(
            template=router_template,
            input_variables=["input"],
            output_parser=None
        )
        
        router_chain = LLMRouterChain.from_llm(
            llm=self.llm,
            prompt=router_prompt
        )
        
        # åˆ›å»ºå¤šè·¯ç”±é“¾
        destination_chains = {
            "internal_medicine": internal_medicine_chain,
            "surgery": surgery_chain,
            "pediatrics": pediatrics_chain
        }
        
        multi_route_chain = MultiRouteChain(
            router_chain=router_chain,
            destination_chains=destination_chains,
            default_chain=default_chain,
            verbose=True
        )
        
        return multi_route_chain
    
    # ==================== 4. è®°å¿†é“¾ (Memory Chain) ====================
    def create_memory_chain(self) -> LLMChain:
        """åˆ›å»ºå¸¦è®°å¿†çš„é“¾ - è¿ç»­å¯¹è¯"""
        
        memory = ConversationBufferWindowMemory(
            memory_key="chat_history",
            input_key="query",
            k=5  # ä¿ç•™æœ€è¿‘5è½®å¯¹è¯
        )
        
        prompt = PromptTemplate(
            input_variables=["chat_history", "query"],
            template="""
            ä»¥ä¸‹æ˜¯æˆ‘ä»¬ä¹‹å‰çš„å¯¹è¯å†å²ï¼š
            {chat_history}
            
            å½“å‰é—®é¢˜ï¼š{query}
            
            ä½œä¸ºåŒ»ç–—åŠ©æ‰‹ï¼Œè¯·åŸºäºå¯¹è¯å†å²ä¸ºæ‚£è€…æä¾›è¿è´¯çš„åŒ»ç–—å»ºè®®ã€‚
            
            å›ç­”ï¼š
            """
        )
        
        memory_chain = LLMChain(
            llm=self.llm,
            prompt=prompt,
            memory=memory,
            verbose=True
        )
        
        return memory_chain
    
    # ==================== 5. è‡ªå®šä¹‰è¾“å‡ºè§£æå™¨ ====================
    class MedicalAnalysisParser(BaseOutputParser):
        """åŒ»ç–—åˆ†æç»“æœè§£æå™¨"""
        
        def parse(self, text: str) -> Dict[str, str]:
            """è§£æåŒ»ç–—åˆ†æç»“æœ"""
            result = {}
            
            # ç®€å•è§£æé€»è¾‘
            if "è¯Šæ–­" in text or "å¯èƒ½" in text:
                result["diagnosis"] = text.split("è¯Šæ–­")[-1].split("\n")[0] if "è¯Šæ–­" in text else "éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥"
            
            if "å»ºè®®" in text:
                result["recommendations"] = text.split("å»ºè®®")[-1].split("\n")[0] if "å»ºè®®" in text else "æš‚æ— å»ºè®®"
            
            if "æ³¨æ„" in text:
                result["precautions"] = text.split("æ³¨æ„")[-1].split("\n")[0] if "æ³¨æ„" in text else "æš‚æ— æ³¨æ„äº‹é¡¹"
            
            result["full_analysis"] = text
            
            return result
    
    def create_parsed_chain(self) -> LLMChain:
        """åˆ›å»ºå¸¦è§£æå™¨çš„é“¾"""
        
        prompt = PromptTemplate(
            input_variables=["symptoms"],
            template="""
            ç—‡çŠ¶ï¼š{symptoms}
            
            è¯·æä¾›ï¼š
            1. å¯èƒ½çš„è¯Šæ–­
            2. æ²»ç–—å»ºè®®
            3. æ³¨æ„äº‹é¡¹
            
            å›ç­”ï¼š
            """
        )
        
        chain = LLMChain(
            llm=self.llm,
            prompt=prompt,
            output_parser=self.MedicalAnalysisParser()
        )
        
        return chain
    
    # ==================== 6. å·¥å…·å®šä¹‰ ====================
    class PatientInfoTool(BaseTool):
        """æ‚£è€…ä¿¡æ¯æŸ¥è¯¢å·¥å…·"""
        name = "patient_info_lookup"
        description = "ç”¨äºæŸ¥è¯¢æ‚£è€…åŸºæœ¬ä¿¡æ¯ï¼Œè¾“å…¥æ‚£è€…ID"
        
        def _run(self, patient_id: str) -> str:
            # æ¨¡æ‹Ÿæ‚£è€…ä¿¡æ¯æŸ¥è¯¢
            patient_data = {
                "001": "å¼ ä¸‰ï¼Œç”·ï¼Œ45å²ï¼Œæ‚£æœ‰é«˜è¡€å‹å’Œç³–å°¿ç—…",
                "002": "æå››ï¼Œå¥³ï¼Œ32å²ï¼Œæ— æ—¢å¾€ç—…å²",
                "003": "ç‹äº”ï¼Œç”·ï¼Œ65å²ï¼Œæœ‰å¿ƒè„ç—…å²"
            }
            
            return patient_data.get(patient_id, "æœªæ‰¾åˆ°è¯¥æ‚£è€…ä¿¡æ¯")
        
        def _arun(self, patient_id: str) -> str:
            return self._run(patient_id)
    
    class SymptomAnalysisTool(BaseTool):
        """ç—‡çŠ¶åˆ†æå·¥å…·"""
        name = "symptom_analysis"
        description = "ç”¨äºåˆ†ææ‚£è€…ç—‡çŠ¶ï¼Œè¾“å…¥ç—‡çŠ¶æè¿°"
        
        def _run(self, symptoms: str) -> str:
            # ç®€å•çš„ç—‡çŠ¶åˆ†æé€»è¾‘
            if "å‘çƒ­" in symptoms:
                return "å¯èƒ½å­˜åœ¨æ„ŸæŸ“ï¼Œå»ºè®®æ£€æŸ¥è¡€å¸¸è§„"
            elif "èƒ¸ç—›" in symptoms:
                return "éœ€è¦æ’é™¤å¿ƒè„ç–¾ç—…ï¼Œå»ºè®®åšå¿ƒç”µå›¾"
            elif "å¤´ç—›" in symptoms:
                return "å¯èƒ½ä¸ºåå¤´ç—›æˆ–è¡€å‹é—®é¢˜ï¼Œå»ºè®®æµ‹é‡è¡€å‹"
            else:
                return "éœ€è¦æ›´è¯¦ç»†çš„ç—‡çŠ¶æè¿°è¿›è¡Œåˆ†æ"
        
        def _arun(self, symptoms: str) -> str:
            return self._run(symptoms)
    
    # ==================== 7. Agent å·¥ä½œæµ ====================
    def create_agent_workflow(self) -> AgentExecutor:
        """åˆ›å»ºAgentå·¥ä½œæµ"""
        
        # åˆ›å»ºå·¥å…·
        tools = [
            self.PatientInfoTool(),
            self.SymptomAnalysisTool()
        ]
        
        # åˆ›å»ºAgentæç¤º
        agent_prompt = PromptTemplate(
            input_variables=["input", "agent_scratchpad"],
            template="""
            ä½ æ˜¯ä¸€ä¸ªåŒ»ç–—åŠ©æ‰‹Agentï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
            
            {tools}
            
            ç”¨æˆ·è¾“å…¥ï¼š{input}
            
            æ€è€ƒè¿‡ç¨‹ï¼š
            {agent_scratchpad}
            
            è¯·ä½¿ç”¨é€‚å½“çš„å·¥å…·æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
            """
        )
        
        # åˆ›å»ºAgent
        agent = create_react_agent(
            llm=self.llm,
            tools=tools,
            prompt=agent_prompt
        )
        
        # åˆ›å»ºAgentæ‰§è¡Œå™¨
        agent_executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True,
            handle_parsing_errors=True
        )
        
        return agent_executor
    
    # ==================== 8. LCEL ç®¡é“æ“ä½œç¬¦å·¥ä½œæµ ====================
    def create_lcel_pipeline_workflow(self) -> Dict[str, Any]:
        """åˆ›å»ºä½¿ç”¨ | ç®¡é“æ“ä½œç¬¦çš„ LCEL å·¥ä½œæµ"""
        
        # 1. ç®€å•ç®¡é“é“¾ - ç—‡çŠ¶åˆ†æ
        simple_pipeline = (
            PromptTemplate.from_template(
                "ä½œä¸ºåŒ»ç–—åŠ©æ‰‹ï¼Œåˆ†æä»¥ä¸‹ç—‡çŠ¶ï¼š{symptoms}\nè¯·æä¾›ç®€æ´çš„åˆ†æï¼š"
            )
            | self.llm
            | StrOutputParser()
        )
        
        # 2. å¤æ‚ç®¡é“é“¾ - å¤šæ­¥éª¤å¤„ç†
        # ç¬¬ä¸€æ­¥ï¼šæå–æ‚£è€…ä¿¡æ¯
        extract_info_prompt = PromptTemplate.from_template(
            """ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–æ‚£è€…ä¿¡æ¯ï¼š
            {input_text}
            
            è¯·æå–ï¼šå¹´é¾„ã€æ€§åˆ«ã€ä¸»è¦ç—‡çŠ¶
            æ ¼å¼ï¼šå¹´é¾„ï¼šXå²ï¼Œæ€§åˆ«ï¼šXï¼Œç—‡çŠ¶ï¼šX"""
        )
        
        # ç¬¬äºŒæ­¥ï¼šç—‡çŠ¶åˆ†æ
        analyze_symptoms_prompt = PromptTemplate.from_template(
            """åŸºäºæ‚£è€…ä¿¡æ¯è¿›è¡Œç—‡çŠ¶åˆ†æï¼š
            {patient_info}
            
            è¯·æä¾›å¯èƒ½çš„è¯Šæ–­å’Œå»ºè®®æ£€æŸ¥ï¼š"""
        )
        
        # ç¬¬ä¸‰æ­¥ï¼šæ²»ç–—å»ºè®®
        treatment_prompt = PromptTemplate.from_template(
            """åŸºäºä»¥ä¸‹ä¿¡æ¯æä¾›æ²»ç–—å»ºè®®ï¼š
            æ‚£è€…ä¿¡æ¯ï¼š{patient_info}
            ç—‡çŠ¶åˆ†æï¼š{symptom_analysis}
            
            è¯·æä¾›æ²»ç–—å»ºè®®å’Œæ³¨æ„äº‹é¡¹ï¼š"""
        )
        
        # ç»„åˆæˆå¤æ‚ç®¡é“
        complex_pipeline = (
            {
                "patient_info": extract_info_prompt | self.llm | StrOutputParser(),
                "input_text": RunnablePassthrough()
            }
            | RunnablePassthrough.assign(
                symptom_analysis=analyze_symptoms_prompt | self.llm | StrOutputParser()
            )
            | treatment_prompt
            | self.llm
            | StrOutputParser()
        )
        
        # 3. å¹¶è¡Œå¤„ç†ç®¡é“
        parallel_analysis_pipeline = RunnableParallel(
            # å†…ç§‘åˆ†æ
            internal_medicine=(
                PromptTemplate.from_template(
                    "ä»å†…ç§‘è§’åº¦åˆ†æï¼š{symptoms}\nå†…ç§‘å»ºè®®ï¼š"
                )
                | self.llm
                | StrOutputParser()
            ),
            # æ€¥è¯Šç§‘åˆ†æ
            emergency=(
                PromptTemplate.from_template(
                    "ä»æ€¥è¯Šç§‘è§’åº¦è¯„ä¼°ï¼š{symptoms}\nç´§æ€¥ç¨‹åº¦å’Œå¤„ç†ï¼š"
                )
                | self.llm
                | StrOutputParser()
            ),
            # é¢„é˜²åŒ»å­¦åˆ†æ
            preventive=(
                PromptTemplate.from_template(
                    "ä»é¢„é˜²åŒ»å­¦è§’åº¦å»ºè®®ï¼š{symptoms}\né¢„é˜²æªæ–½ï¼š"
                )
                | self.llm
                | StrOutputParser()
            )
        )
        
        # 4. æ¡ä»¶åˆ†æ”¯ç®¡é“
        def route_by_age(inputs):
            """æ ¹æ®å¹´é¾„è·¯ç”±åˆ°ä¸åŒçš„åˆ†æç®¡é“"""
            age_text = inputs.get("age", "")
            try:
                age = int(age_text)
                if age < 18:
                    return "pediatric"
                elif age >= 65:
                    return "geriatric"
                else:
                    return "adult"
            except:
                return "adult"
        
        # å„¿ç§‘ç®¡é“
        pediatric_pipeline = (
            PromptTemplate.from_template(
                "å„¿ç§‘åŒ»ç”Ÿåˆ†æï¼šæ‚£è€…{age}å²ï¼Œç—‡çŠ¶ï¼š{symptoms}\nå„¿ç§‘ä¸“ä¸šå»ºè®®ï¼š"
            )
            | self.llm
            | StrOutputParser()
        )
        
        # æˆäººç®¡é“
        adult_pipeline = (
            PromptTemplate.from_template(
                "æˆäººåŒ»å­¦åˆ†æï¼šæ‚£è€…{age}å²ï¼Œç—‡çŠ¶ï¼š{symptoms}\næˆäººåŒ»å­¦å»ºè®®ï¼š"
            )
            | self.llm
            | StrOutputParser()
        )
        
        # è€å¹´åŒ»å­¦ç®¡é“
        geriatric_pipeline = (
            PromptTemplate.from_template(
                "è€å¹´åŒ»å­¦åˆ†æï¼šæ‚£è€…{age}å²ï¼Œç—‡çŠ¶ï¼š{symptoms}\nè€å¹´åŒ»å­¦ä¸“ä¸šå»ºè®®ï¼š"
            )
            | self.llm
            | StrOutputParser()
        )
        
        # 5. å¸¦è®°å¿†çš„ç®¡é“é“¾
        memory_pipeline = (
            {
                "input": lambda x: x["input"],
                "chat_history": lambda x: x.get("chat_history", [])
            }
            | PromptTemplate.from_template(
                """å¯¹è¯å†å²ï¼š{chat_history}
                
                å½“å‰é—®é¢˜ï¼š{input}
                
                ä½œä¸ºåŒ»ç–—åŠ©æ‰‹ï¼ŒåŸºäºå¯¹è¯å†å²æä¾›è¿è´¯çš„å›ç­”ï¼š"""
            )
            | self.llm
            | StrOutputParser()
        )
        
        # 6. å¤šæ ¼å¼è¾“å‡ºç®¡é“
        structured_output_pipeline = (
            PromptTemplate.from_template(
                """åˆ†æç—‡çŠ¶ï¼š{symptoms}
                
                è¯·ä»¥ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š
                {{
                    "diagnosis": "å¯èƒ½è¯Šæ–­",
                    "severity": "ä¸¥é‡ç¨‹åº¦(è½»åº¦/ä¸­åº¦/é‡åº¦)",
                    "urgency": "ç´§æ€¥ç¨‹åº¦(ä½/ä¸­/é«˜)",
                    "recommendations": ["å»ºè®®1", "å»ºè®®2"],
                    "next_steps": "ä¸‹ä¸€æ­¥è¡ŒåŠ¨"
                }}"""
            )
            | self.llm
            | StrOutputParser()
        )
        
        return {
            "simple_pipeline": simple_pipeline,
            "complex_pipeline": complex_pipeline,
            "parallel_analysis": parallel_analysis_pipeline,
            "conditional_routing": {
                "router": route_by_age,
                "pediatric": pediatric_pipeline,
                "adult": adult_pipeline,
                "geriatric": geriatric_pipeline
            },
            "memory_pipeline": memory_pipeline,
            "structured_output": structured_output_pipeline
        }
    
    # ==================== 9. å¤åˆå·¥ä½œæµ ====================
    async def create_complex_workflow(self) -> Dict[str, Any]:
        """åˆ›å»ºå¤åˆå·¥ä½œæµ - ç»“åˆå¤šç§é“¾"""
        
        # æ‚£è€…ä¿¡æ¯é¢„å¤„ç†é“¾
        preprocess_prompt = PromptTemplate(
            input_variables=["raw_input"],
            template="""
            åŸå§‹è¾“å…¥ï¼š{raw_input}
            
            è¯·æå–å…¶ä¸­çš„å…³é”®ä¿¡æ¯ï¼š
            1. æ‚£è€…åŸºæœ¬ä¿¡æ¯ï¼ˆå¹´é¾„ã€æ€§åˆ«ç­‰ï¼‰
            2. ç—‡çŠ¶æè¿°
            3. æŸ¥è¯¢ç±»å‹ï¼ˆè¯Šæ–­ã€æ²»ç–—ã€é¢„é˜²ç­‰ï¼‰
            
            è¾“å‡ºæ ¼å¼ï¼š
            åŸºæœ¬ä¿¡æ¯ï¼š
            ç—‡çŠ¶ï¼š
            æŸ¥è¯¢ç±»å‹ï¼š
            """
        )
        
        preprocess_chain = LLMChain(
            llm=self.llm,
            prompt=preprocess_prompt,
            output_key="processed_info"
        )
        
        # ä¸“ä¸šåˆ†æé“¾
        analysis_prompt = PromptTemplate(
            input_variables=["processed_info"],
            template="""
            åŸºäºä»¥ä¸‹ä¿¡æ¯è¿›è¡Œä¸“ä¸šåˆ†æï¼š
            {processed_info}
            
            è¯·æä¾›ï¼š
            1. ä¸“ä¸šçš„åŒ»ç–—åˆ†æ
            2. è¯Šæ–­å»ºè®®
            3. æ²»ç–—æ–¹æ¡ˆ
            4. æ³¨æ„äº‹é¡¹
            
            å›ç­”ï¼š
            """
        )
        
        analysis_chain = LLMChain(
            llm=self.llm,
            prompt=analysis_prompt,
            output_key="analysis_result"
        )
        
        # æŠ¥å‘Šç”Ÿæˆé“¾
        report_prompt = PromptTemplate(
            input_variables=["processed_info", "analysis_result"],
            template="""
            æ‚£è€…ä¿¡æ¯ï¼š{processed_info}
            
            åˆ†æç»“æœï¼š{analysis_result}
            
            è¯·ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„åŒ»ç–—æŠ¥å‘Šï¼ŒåŒ…å«ï¼š
            1. æ‚£è€…æ‘˜è¦
            2. ç—‡çŠ¶åˆ†æ
            3. è¯Šæ–­ç»“è®º
            4. æ²»ç–—å»ºè®®
            5. éšè®¿è®¡åˆ’
            
            åŒ»ç–—æŠ¥å‘Šï¼š
            """
        )
        
        report_chain = LLMChain(
            llm=self.llm,
            prompt=report_prompt,
            output_key="medical_report"
        )
        
        # ç»„åˆæˆå¤åˆé“¾
        complex_chain = SequentialChain(
            chains=[preprocess_chain, analysis_chain, report_chain],
            input_variables=["raw_input"],
            output_variables=["processed_info", "analysis_result", "medical_report"],
            verbose=True
        )
        
        return {
            "complex_chain": complex_chain,
            "preprocess_chain": preprocess_chain,
            "analysis_chain": analysis_chain,
            "report_chain": report_chain
        }
    
    # ==================== 10. æ¼”ç¤ºå‡½æ•° ====================
    async def demonstrate_workflows(self):
        """æ¼”ç¤ºæ‰€æœ‰å·¥ä½œæµ"""
        print("="*60)
        print("ğŸ¥ LangChain åŒ»ç–—å·¥ä½œæµæ¼”ç¤º")
        print("="*60)
        
        # 1. ç®€å•é“¾æ¼”ç¤º
        print("\n1ï¸âƒ£ ç®€å•é“¾æ¼”ç¤º - ç—‡çŠ¶åˆ†æ")
        print("-" * 40)
        simple_chain = self.create_simple_chain()
        result = simple_chain.run({
            "symptoms": "å¤´ç—›ã€å‘çƒ­ã€å’³å—½",
            "patient_age": "35",
            "gender": "å¥³"
        })
        print(f"åˆ†æç»“æœï¼š{result}")
        
        # 2. é¡ºåºé“¾æ¼”ç¤º
        print("\n2ï¸âƒ£ é¡ºåºé“¾æ¼”ç¤º - å®Œæ•´åŒ»ç–—æµç¨‹")
        print("-" * 40)
        sequential_chain = self.create_sequential_chain()
        result = sequential_chain.run({
            "symptoms": "èƒ¸ç—›ã€æ°”çŸ­",
            "patient_info": "45å²ç”·æ€§ï¼Œæœ‰é«˜è¡€å‹å²"
        })
        print(f"ç—‡çŠ¶åˆ†æï¼š{result['symptom_analysis']}")
        print(f"æ£€æŸ¥è®¡åˆ’ï¼š{result['examination_plan']}")
        print(f"æ²»ç–—æ–¹æ¡ˆï¼š{result['treatment_plan']}")
        
        # 3. åˆ†æ”¯é“¾æ¼”ç¤º
        print("\n3ï¸âƒ£ åˆ†æ”¯é“¾æ¼”ç¤º - ç§‘å®¤åˆ†å‘")
        print("-" * 40)
        router_chain = self.create_router_chain()
        result = router_chain.run("3å²å„¿ç«¥åå¤å‘çƒ­")
        print(f"ä¸“ç§‘å»ºè®®ï¼š{result}")
        
        # 4. è®°å¿†é“¾æ¼”ç¤º
        print("\n4ï¸âƒ£ è®°å¿†é“¾æ¼”ç¤º - è¿ç»­å¯¹è¯")
        print("-" * 40)
        memory_chain = self.create_memory_chain()
        
        # ç¬¬ä¸€è½®å¯¹è¯
        result1 = memory_chain.run("æˆ‘æœ‰ç‚¹å¤´ç—›")
        print(f"ç¬¬ä¸€è½®å›ç­”ï¼š{result1}")
        
        # ç¬¬äºŒè½®å¯¹è¯
        result2 = memory_chain.run("è¿™ç§æƒ…å†µæŒç»­äº†ä¸‰å¤©")
        print(f"ç¬¬äºŒè½®å›ç­”ï¼š{result2}")
        
        # 5. è§£æå™¨é“¾æ¼”ç¤º
        print("\n5ï¸âƒ£ è§£æå™¨é“¾æ¼”ç¤º - ç»“æ„åŒ–è¾“å‡º")
        print("-" * 40)
        parsed_chain = self.create_parsed_chain()
        result = parsed_chain.run("è…¹ç—›ã€æ¶å¿ƒã€å‘•å")
        print(f"è§£æç»“æœï¼š{result}")
        
        # 6. Agentæ¼”ç¤º
        print("\n6ï¸âƒ£ Agentæ¼”ç¤º - å·¥å…·ä½¿ç”¨")
        print("-" * 40)
        agent = self.create_agent_workflow()
        result = agent.run("æŸ¥è¯¢æ‚£è€…001çš„ä¿¡æ¯ï¼Œå¹¶åˆ†æå‘çƒ­ç—‡çŠ¶")
        print(f"Agentç»“æœï¼š{result}")
        
        # 7. LCEL ç®¡é“æ“ä½œç¬¦æ¼”ç¤º
        print("\n7ï¸âƒ£ LCEL ç®¡é“æ“ä½œç¬¦æ¼”ç¤º - ç°ä»£è¯­æ³•")
        print("-" * 40)
        lcel_workflows = self.create_lcel_pipeline_workflow()
        
        # 7.1 ç®€å•ç®¡é“æ¼”ç¤º
        print("  ğŸ“Œ ç®€å•ç®¡é“ (prompt | llm | parser):")
        simple_result = lcel_workflows["simple_pipeline"].invoke({
            "symptoms": "æŒç»­æ€§å¤´ç—›ä¼´æ¶å¿ƒ"
        })
        print(f"    ç»“æœ: {simple_result}")
        
        # 7.2 å¹¶è¡Œå¤„ç†ç®¡é“æ¼”ç¤º
        print("\n  ğŸ“Œ å¹¶è¡Œåˆ†æç®¡é“:")
        parallel_result = lcel_workflows["parallel_analysis"].invoke({
            "symptoms": "èƒ¸é—·ã€å¿ƒæ‚¸ã€å‡ºæ±—"
        })
        print(f"    å†…ç§‘è§‚ç‚¹: {parallel_result['internal_medicine']}")
        print(f"    æ€¥è¯Šè§‚ç‚¹: {parallel_result['emergency']}")
        print(f"    é¢„é˜²è§‚ç‚¹: {parallel_result['preventive']}")
        
        # 7.3 æ¡ä»¶è·¯ç”±ç®¡é“æ¼”ç¤º
        print("\n  ğŸ“Œ æ¡ä»¶è·¯ç”±ç®¡é“:")
        routing_config = lcel_workflows["conditional_routing"]
        
        # å„¿ç«¥æ‚£è€…
        child_input = {"age": "8", "symptoms": "å‘çƒ­ã€å’³å—½"}
        route = routing_config["router"](child_input)
        child_result = routing_config[route].invoke(child_input)
        print(f"    å„¿ç«¥æ‚£è€…è·¯ç”±åˆ°: {route}")
        print(f"    åˆ†æç»“æœ: {child_result}")
        
        # è€å¹´æ‚£è€…
        elderly_input = {"age": "75", "symptoms": "èƒ¸ç—›ã€æ°”çŸ­"}
        route = routing_config["router"](elderly_input)
        elderly_result = routing_config[route].invoke(elderly_input)
        print(f"    è€å¹´æ‚£è€…è·¯ç”±åˆ°: {route}")
        print(f"    åˆ†æç»“æœ: {elderly_result}")
        
        # 7.4 ç»“æ„åŒ–è¾“å‡ºç®¡é“æ¼”ç¤º
        print("\n  ğŸ“Œ ç»“æ„åŒ–è¾“å‡ºç®¡é“:")
        structured_result = lcel_workflows["structured_output"].invoke({
            "symptoms": "å‰§çƒˆè…¹ç—›ã€å‘•åã€å‘çƒ­"
        })
        print(f"    JSONæ ¼å¼è¾“å‡º: {structured_result}")
        
        # 7.5 è®°å¿†ç®¡é“æ¼”ç¤º
        print("\n  ğŸ“Œ è®°å¿†ç®¡é“æ¼”ç¤º:")
        memory_pipeline = lcel_workflows["memory_pipeline"]
        
        # ç¬¬ä¸€è½®å¯¹è¯
        result1 = memory_pipeline.invoke({
            "input": "æˆ‘ç»å¸¸å¤´ç—›",
            "chat_history": []
        })
        print(f"    ç¬¬ä¸€è½®: {result1}")
        
        # ç¬¬äºŒè½®å¯¹è¯ï¼ˆå¸¦å†å²ï¼‰
        result2 = memory_pipeline.invoke({
            "input": "è¿™ç§å¤´ç—›å·²ç»æŒç»­ä¸€å‘¨äº†",
            "chat_history": [f"ç”¨æˆ·: æˆ‘ç»å¸¸å¤´ç—›\nåŠ©æ‰‹: {result1}"]
        })
        print(f"    ç¬¬äºŒè½®: {result2}")
        
        # 8. å¤åˆå·¥ä½œæµæ¼”ç¤º
        print("\n8ï¸âƒ£ å¤åˆå·¥ä½œæµæ¼”ç¤º - ç»¼åˆåˆ†æ")
        print("-" * 40)
        complex_workflows = await self.create_complex_workflow()
        complex_chain = complex_workflows["complex_chain"]
        result = complex_chain.run({
            "raw_input": "æˆ‘æ˜¯30å²å¥³æ€§ï¼Œæœ€è¿‘å‡ å¤©ä¸€ç›´å¤´ç—›ï¼Œè¿˜ä¼´æœ‰æ¶å¿ƒç—‡çŠ¶ï¼Œè¯·å¸®æˆ‘åˆ†æä¸€ä¸‹"
        })
        print(f"åŒ»ç–—æŠ¥å‘Šï¼š{result['medical_report']}")
        
        print("\n" + "="*60)
        print("ğŸ‰ æ‰€æœ‰8ç§å·¥ä½œæµæ¼”ç¤ºå®Œæˆï¼")
        print("åŒ…å«ï¼šç®€å•é“¾ã€é¡ºåºé“¾ã€åˆ†æ”¯é“¾ã€è®°å¿†é“¾ã€è§£æå™¨é“¾ã€Agentå·¥ä½œæµã€LCELç®¡é“æ“ä½œç¬¦ã€å¤åˆå·¥ä½œæµ")
        print("="*60)

# ==================== ä¸»å‡½æ•° ====================
async def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºå·¥ä½œæµå®ä¾‹
        workflow = MedicalWorkflowExample()
        
        # è¿è¡Œæ¼”ç¤º
        await workflow.demonstrate_workflows()
        
    except Exception as e:
        logger.error(f"è¿è¡Œå‡ºé”™: {e}")
        print(f"âŒ é”™è¯¯ï¼š{e}")
        print("è¯·æ£€æŸ¥ï¼š")
        print("1. OPENAI_API_KEY æ˜¯å¦æ­£ç¡®è®¾ç½®")
        print("2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("3. ä¾èµ–åº“æ˜¯å¦æ­£ç¡®å®‰è£…")

if __name__ == "__main__":
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main()) 